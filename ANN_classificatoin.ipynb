{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "PAuBOgfg2agc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "\n",
        "Y = iris.target_names[iris.target]\n",
        "\n",
        "X = iris_df.drop('sepal length (cm)', axis=1)"
      ],
      "metadata": {
        "id": "QHZsv-tt8WrI"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = map(np.array, train_test_split(X, Y, test_size=0.2, random_state=42))\n",
        "y_train = np.array(pd.get_dummies(y_train))"
      ],
      "metadata": {
        "id": "DNker_jzJIBa"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_rate = 0.01\n",
        "\n",
        "echo  = 10000 # iterations\n",
        "\n",
        "input_size = len(x_train[0])\n",
        "hidden_lay = [8]\n",
        "output_size = len(set(Y))\n"
      ],
      "metadata": {
        "id": "JVjnZEjs2q0c"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(p):\n",
        "     return 1 / (1 + np.exp(-p))"
      ],
      "metadata": {
        "id": "4RynwXPJ2l-P"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb = -1\n",
        "ub = 1\n",
        "\n",
        "def initialize_weights(input_size, hidden_layers, output_size, lb, ub):\n",
        "    weight_mat = []\n",
        "\n",
        "    # Initialize weights for the first layer\n",
        "    w_first = np.random.randn(input_size, hidden_layers[0]) * (ub - lb) + lb\n",
        "    weight_mat.append(w_first)\n",
        "\n",
        "    # Initialize weights for the hidden layers\n",
        "    for i in range(len(hidden_layers) - 1):\n",
        "        wei = np.random.randn(hidden_layers[i], hidden_layers[i+1]) * (ub - lb) + lb\n",
        "        weight_mat.append(wei)\n",
        "\n",
        "    # Initialize weights for the last layer\n",
        "    w_last = np.random.randn(hidden_layers[-1], output_size) * (ub - lb) + lb\n",
        "    weight_mat.append(w_last)\n",
        "\n",
        "    return weight_mat\n",
        "\n",
        "def initialize_biases(hidden_layers, output_nodes, lb, ub):\n",
        "    bias_mat = []\n",
        "\n",
        "    # Initialize biases for the hidden layers\n",
        "    for hidden_nodes in hidden_layers:\n",
        "        b = np.random.rand(hidden_nodes) * (ub - lb) + lb\n",
        "        bias_mat.append(b)\n",
        "\n",
        "    # Initialize biases for the output layer\n",
        "    b = np.random.rand(output_nodes) * (ub - lb) + lb\n",
        "    bias_mat.append(b)\n",
        "\n",
        "    return bias_mat\n",
        "\n"
      ],
      "metadata": {
        "id": "fy9ram015TKf"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(x_train, weight_matrices, bias_matrices):\n",
        "    values = []\n",
        "    for i, weight_mat in enumerate(weight_matrices):\n",
        "        if i == 0:\n",
        "            v = np.dot(x_train, weight_mat) + bias_matrices[i]\n",
        "        else:\n",
        "            v = np.dot(values[-1], weight_mat) + bias_matrices[i]\n",
        "        v = np.array([sigmoid(val) for val in v])  # Apply sigmoid activation function\n",
        "        values.append(v)\n",
        "    return values\n",
        "\n",
        "def backward_propagation(y_train, values, weight_matrices):\n",
        "    errors = []\n",
        "    error = (values[-1] * (1 - values[-1])) * (y_train - values[-1])\n",
        "    errors.append(error)\n",
        "\n",
        "    for i in range(len(hidden_lay)-1, -1, -1):\n",
        "        h = (values[i] * (1 - values[i])) * (errors[-1] @ weight_matrices[i+1].T)\n",
        "        errors.append(h)\n",
        "    errors.reverse()\n",
        "    return errors\n",
        "\n",
        "def update_weights(x_train, values, errors, weight_matrices, bias_matrices, l_rate):\n",
        "    for i, weight_mat in enumerate(weight_matrices):\n",
        "        if i == 0:\n",
        "            del_w = l_rate * (x_train.T @ errors[i])\n",
        "        else:\n",
        "            del_w = l_rate * (values[i-1].T @ errors[i])\n",
        "        weight_matrices[i] += del_w\n",
        "\n",
        "    for i, bias_mat in enumerate(bias_matrices):\n",
        "        bias_matrices[i] += l_rate * np.sum(errors[i], axis=0)\n",
        "\n",
        "def train_neural_network(x_train, y_train, weight_matrices, bias_matrices, l_rate, epochs):\n",
        "    for _ in range(epochs):\n",
        "        # Forward propagation\n",
        "        values = forward_propagation(x_train, weight_matrices, bias_matrices)\n",
        "\n",
        "        # Backward propagation\n",
        "        errors = backward_propagation(y_train, values, weight_matrices)\n",
        "\n",
        "        # Update weights and biases\n",
        "        update_weights(x_train, values, errors, weight_matrices, bias_matrices, l_rate)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hgap396BwW2E"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for forward propagation on new data\n",
        "def forward_propagation_new_data(new_x, weight_matrices, bias_matrices):\n",
        "    predictions = []\n",
        "    for i, weight_mat in enumerate(weight_matrices):\n",
        "        if i == 0:\n",
        "            v = np.dot(new_x, weight_mat) + bias_matrices[i]\n",
        "        else:\n",
        "            v = np.dot(predictions[-1], weight_mat) + bias_matrices[i]\n",
        "        v = np.array([sigmoid(val) for val in v])  # Apply sigmoid activation function\n",
        "        predictions.append(v)\n",
        "    return predictions\n",
        "\n",
        "# Function for predicting classes\n",
        "def predict_classes(new_x, weight_matrices, bias_matrices, threshold=0.5):\n",
        "    predictions = forward_propagation_new_data(new_x, weight_matrices, bias_matrices)\n",
        "    final_predictions = (predictions[-1] >= threshold).astype(int)\n",
        "    return final_predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "wIY78193V6aT"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_mat = initialize_weights(input_size, hidden_lay, output_size, lb, ub)\n",
        "bias_mat = initialize_biases(hidden_lay, output_size, lb, ub)\n",
        "\n",
        "train_neural_network(x_train, y_train, weight_mat, bias_mat, l_rate, echo)"
      ],
      "metadata": {
        "id": "rlgE9wgHcVoh"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming weight_matrices, bias_matrices, x_test are defined\n",
        "threshold = 0.5\n",
        "final_predictions = predict_classes(x_test, weight_mat, bias_mat, threshold)\n",
        "\n",
        "# Convert predictions to one-hot encoded format\n",
        "encoded_output = final_predictions\n",
        "df_encoded_output = pd.DataFrame(encoded_output, columns=['setosa', 'versicolor', 'virginica'])\n",
        "\n",
        "# Decode predictions to class labels\n",
        "decoded_output = df_encoded_output.idxmax(axis=1)"
      ],
      "metadata": {
        "id": "5FY1uk6MWvXK"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, decoded_output)\n",
        "print(\"Accuracy:\", accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSYT6Q7vB-oY",
        "outputId": "85be67a8-6752-4449-9a49-8c6fef87724a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.66666666666667\n"
          ]
        }
      ]
    }
  ]
}